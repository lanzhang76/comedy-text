{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2_transcripts.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanzhang76/comedy-text/blob/master/gpt2_transcripts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZIy5IGFScRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a374d4fc-be60-4dcd-e50d-96744a3a5769"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 27.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 33.5MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 4.3MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.2MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71kB 5.9MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 266kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 276kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 286kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 296kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 307kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 317kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 327kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 337kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 348kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 358kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 368kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 378kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 389kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 399kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 409kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 419kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 430kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 440kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 450kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 460kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 471kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 481kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 491kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 501kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 512kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 522kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 532kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 542kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 552kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 563kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 573kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 583kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 593kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 604kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 614kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 624kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 634kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 645kB 7.8MB/s \n",
            "\u001b[?25h  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlHtKjqESqTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vMIzelTU1CC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "check which gpu is being used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRa4ph1uTSpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a8c907f0-6113-4b27-c3d7-adafa9b2b8b5"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iETbZiBzTTMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTq8vmh3UREz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwycIxBkUahw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "33029a6d-dc30-40f8-ca2e-de45ef92bdaf"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-QGeWziVJTF",
        "colab_type": "text"
      },
      "source": [
        "return list: set return_as_list=True)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssTrADaEUjYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "daa659d7-de9d-473c-c626-a5c1ba1a55c7"
      },
      "source": [
        "text = gpt2.generate(sess, return_as_list=True)[0]\n",
        "text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'How can a person be honest when they are so afraid of something that is happening to them? I’m not really sure how a person can be honest when they are so afraid of something that is happening to them. It doesn’t exist.” There’s no such thing as fear. There’s no such thing as fear. I don’t know why it’s such a big deal, but the fear of something happening to me really exists. I think it’s a thing. I think it’s a thing because it drives people crazy. People think they’re crazy when they’re not crazy. They think they’re crazy. They’re crazy when they’re not crazy. And they think they’re crazy when they’re not crazy. And they think they’re crazy when they’re not crazy. And they’re crazy when they’re not crazy. It’s a very important thing in our society. It’s a very important thing. It’s a very important thing. And I think we’ve all been so afraid to be crazy that we’ve… We’ve been so afraid of being crazy. I think we’ve all been so scared of being crazy that we have given up on being crazy. I think we’ve been so afraid of being crazy that we have given up on being crazy. I think we’ve given up on being crazy. I think we’ve been so scared of being crazy that we have given up on being crazy. And I think we’ve given up on being crazy because we’ve been so limited. Like, if you go to a casino and there’s a man in a suit and a tie, he’s going to be rude and aggressive and stuff. And I think you’re going to do that. I think you’re going to do that. I think you’re going to do that. But if you go to a mall and you see a guy in a suit and tie, he’s going to be rude and aggressive and stuff. And I think you’re going to do that. But if you go to a restaurant, you’re gonna be rude and aggressive. And I think you’re gonna do that. And I think you’re gonna do that. But if you go to a bar and there’s a guy in a suit and a tie, he’s gonna be rude and aggressive and stuff. And I think you’re gonna do that. But if you go to a wine bar, you’re gonna be rude and aggressive and stuff and he’ll be like, “Can I help you?” And you’re gonna do that, but he’s gonna be like, “Can I help you?” And you’re gonna do that. And I think you’re gonna do that. But if you go to a bar, you’re gonna be rude and aggressive and stuff and he’ll be like, “Can I help you?” And you’re gonna do that. But he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, and he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, and he’ll be like, “Can I help you?” And he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you?” And you’re gonna do that, but he’ll be like, “Can I help you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaEYq7sDkQH9",
        "colab_type": "text"
      },
      "source": [
        "The following script will generate sentence based on the prefix. If prefix is not desired. Set false to prefix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuCTHueMUzVQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "a504b862-7507-408c-b934-c713ed584b99"
      },
      "source": [
        "text = gpt2.generate(sess,\n",
        "              length=200,\n",
        "              temperature=0.7,\n",
        "              prefix=\"hello\",\n",
        "              nsamples=5,\n",
        "              batch_size=5,\n",
        "              include_prefix = True\n",
        "              )"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello, don’t put your forehead against the wall!”', 'Look at me, you crazy. You’re like, “I don’t wanna talk about that.” You’re like… “I’m gonna talk about ’em tomorrow.” Hey, you like talking about ’em? You’re like, “I don’t wanna talk about ’em,” right? You’re like, “I like talking about ’em.” I don’t like talking about ’em. I don’t like talking about ’em. I mean, you know, I know a lot of people. I know a lot of people that are like, “I dunno who’s that.” So, you know, I’m not gonna talk about ’em, but, you know, I can\n",
            "====================\n",
            "hello, do you have a camera?” I’m like, “Yeah…” I’m waiting. I’m waiting. The camera now is opening up. I’m like, “Hello?” The camera is coming up… and it’s just like… I’m like, “What…” I’m like, “No, no, I don’t have a camera.” It’s like, “C is for “I will give you “I’m going to give you a camera.” He’s like, “I’m sorry, I’m sorry.” I’m like, “What?” He’s like, “What are you doing?” I’m like, “You’re in a relationship with your life\n",
            "====================\n",
            "hello, I’m gonna have to take the bus to the airport. I’m gonna take the bus to the airport, and I’m gonna have to get to a special place to bring my ID. I’m gonna wait there all night. I got my ID, I can’t have a special place to bring ID. I’m gonna wait there all night and just have a special place to bring ID. I’m gonna wait there all night and I’m gonna have to drive this bus. I’m gonna drive this bus to the airport. I’m gonna have to get to my special place to bring my ID. And I’m gonna wait there all night, I can’t have ID, oh, my God, I’m so tired. I can’t even get up. I’m so tired. I can’t even get up. I�\n",
            "====================\n",
            "hello, what’s that? That’s what, you know, this is how you can say that. I don’t know. I’m not gonna answer that question, but, you know, I’ve been sleeping all this time. I’ve been sleeping all this time. I’ve been sleeping all this time for this reason, which is, I want to be a fat man. I’ve been sleeping all this time for this reason. I want to be a fat man. I want to be a fat man. I want to be like a fat white man, and I go, “Well, I’ve been sleeping all this time, look, you’re not a fat man.” And I’m a fat white man, and I’m like, “I’m fucking fat, I’m a fat white man.” I want to\n",
            "====================\n",
            "hello, if you’re with another human being, she’s with you. If you’re with another human being, she’s with you. There’s a logic to any situation. If your heart is beating too hard, she’s with you. If your heart is beating too hard, she’ll be in the car. If your heart is beating too hard, she’s with you. It’s always the same, you have to be in the car. I’ve always been in a car. I’ve seen cars. I’ve seen cars. I’ve always been in a car. I’ve seen cars. I’ve seen cars. I have seen cars, and I’ve seen cars. I’ve seen cars. I’ve seen cars. I have seen cars. I’ve seen cars. I’ve seen\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA65vYDNkzHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "507a8782-fb28-484e-e6ea-1cb5f0d876e3"
      },
      "source": [
        "!pip3 install google_speech"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_speech\n",
            "  Downloading https://files.pythonhosted.org/packages/f3/2d/bf479ffe93a0b89a0cb56b0189e9488b0383dad872d4ae2119c024080004/google_speech-1.1.0.tar.gz\n",
            "Collecting appdirs>=1.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from google_speech) (2.21.0)\n",
            "Collecting web_cache>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/67/9970fa9705c2e4234923a1ae0ca96bd5f29571d21b70c5457528347f1eaf/web_cache-1.1.0.tar.gz\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.6.0->google_speech) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.6.0->google_speech) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.6.0->google_speech) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.6.0->google_speech) (1.24.3)\n",
            "Building wheels for collected packages: google-speech, web-cache\n",
            "  Building wheel for google-speech (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-speech: filename=google_speech-1.1.0-cp36-none-any.whl size=18135 sha256=2946016565bc328eb7811d9d3b08e2a0076d09a567a33fcf617a19202f5e59c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/12/78/8e32a965dceac33695245a3528c8a403306881f5fdb5305b9f\n",
            "  Building wheel for web-cache (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for web-cache: filename=web_cache-1.1.0-cp36-none-any.whl size=15440 sha256=2123e807e26b7d3c73065f18e1917e21cc9b9b597ad8fc9fcb8a676c4f6e2a7e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/ab/f2/0b74b98df7580f6b8ca5d2bc9524511bcf2d64835447ce5156\n",
            "Successfully built google-speech web-cache\n",
            "Installing collected packages: appdirs, web-cache, google-speech\n",
            "Successfully installed appdirs-1.4.3 google-speech-1.1.0 web-cache-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shxskGfKlcT_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "198c9841-75ec-4f4b-9579-764767083e0c"
      },
      "source": [
        "!sudo apt-get install sox libsox-fmt-mp3"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up libmad0:amd64 (0.15.1b-9ubuntu18.04.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwKG50KJmilU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google_speech import Speech"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFV7q9evnOl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gtts import gTTS\n",
        "tts = gTTS('hello', lang='en')\n",
        "tts.save('hello.mp3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PSZ2EBYokjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from io import BytesIO\n",
        "mp3_fp = BytesIO()\n",
        "tts = gTTS('hello', 'en')\n",
        "tts.write_to_fp(mp3_fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ-EA1fqpigT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}